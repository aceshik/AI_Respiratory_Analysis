import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from torch.optim.lr_scheduler import ReduceLROnPlateau
import numpy as np
from collections import Counter
from tqdm import tqdm
from sklearn.metrics import classification_report, f1_score
import matplotlib.pyplot as plt

from models.enhanced_model import EnhancedCNNBiLSTM, EnhancedCNNEnsemble, EnhancedCNNDeepBiLSTM

# ë°ì´í„° ë¡œë“œ
X_train = np.load("data2/X_train.npy")
y_train = np.load("data2/y_train.npy")
X_val = np.load("data2/X_val.npy")
y_val = np.load("data2/y_val.npy")

print("ì •ê·œí™” ì´ì „ ë¶„í¬:", Counter(y_train))

# ì •ê·œí™”
X_mean = X_train.mean()
X_std = X_train.std()
X_train = (X_train - X_mean) / X_std
X_val = (X_val - X_mean) / X_std

np.save("data2/X_mean_std.npy", [X_mean, X_std])

# Tensor ë³€í™˜
X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)
X_val = torch.tensor(X_val, dtype=torch.float32)
y_val = torch.tensor(y_val, dtype=torch.long)

# Wheeze ì¦ê°• ë°ì´í„° ì¶”ê°€ (Pitch Shifting)
X_wheeze_ps = np.load("data2/X_wheeze_pitch_padded.npy")
y_wheeze_ps = np.load("data2/y_wheeze_pitch_padded.npy")

print(f"Wheeze ì¦ê°• ë°ì´í„°: {X_wheeze_ps.shape}, {Counter(y_wheeze_ps.tolist())}")

# (B, 200, 13) â†’ (B, 13, 200) for consistency
X_wheeze_ps = np.transpose(X_wheeze_ps, (0, 2, 1))

# ì •ê·œí™”
X_wheeze_ps = (X_wheeze_ps - X_mean) / X_std

# Tensor ë³€í™˜
X_wheeze_ps = torch.tensor(X_wheeze_ps, dtype=torch.float32)
y_wheeze_ps = torch.tensor(y_wheeze_ps, dtype=torch.long)

# concat
X_train = torch.cat([X_train, X_wheeze_ps], dim=0)
y_train = torch.cat([y_train, y_wheeze_ps], dim=0)

print("ì¦ê°• ë°ì´í„° í¬í•¨ í›„ ë¶„í¬:", Counter(y_train.tolist()))

# ë°ì´í„° ì¦ê°•!!!
# 1. ì›ë³¸ ë³´ì¡´
original_X_train = X_train.clone()
original_y_train = y_train.clone()

# 2. íƒ€ê²Ÿ ê°œìˆ˜ ì„¤ì • (ê° í´ë˜ìŠ¤ ê°œìˆ˜ ë§ì¶”ê¸°)
target_per_class = {
    0: 1400,  # Normal
    1: 1400,  # Crackle
    2: 1400   # Wheeze
}

# 3. í´ë˜ìŠ¤ë³„ ì¸ë±ìŠ¤ ì¶”ì¶œ
normal_idx   = (original_y_train == 0).nonzero(as_tuple=True)[0]
crackle_idx  = (original_y_train == 1).nonzero(as_tuple=True)[0]
wheeze_idx   = (original_y_train == 2).nonzero(as_tuple=True)[0]

# 4. í´ë˜ìŠ¤ë³„ ë°ì´í„° ì¶”ì¶œ
X_normal,  y_normal  = original_X_train[normal_idx],  original_y_train[normal_idx]
X_crackle, y_crackle = original_X_train[crackle_idx], original_y_train[crackle_idx]
X_wheeze,  y_wheeze  = original_X_train[wheeze_idx],  original_y_train[wheeze_idx]

# 5. ì¦ê°• í•¨ìˆ˜
def augment_to_target(X_class, y_class, target_count):
    current = len(X_class)
    if current >= target_count:
        return X_class[:target_count], y_class[:target_count]
    repeat_factor = target_count // current
    remainder = target_count % current
    X_aug = X_class.repeat((repeat_factor, 1, 1))
    y_aug = y_class.repeat(repeat_factor)
    if remainder > 0:
        X_aug = torch.cat([X_aug, X_class[:remainder]], dim=0)
        y_aug = torch.cat([y_aug, y_class[:remainder]], dim=0)
    return X_aug, y_aug

# ë³µì‚¬ë³¸ì—ë§Œ ë…¸ì´ì¦ˆ ì¶”ê°€ í•¨ìˆ˜
def augment_to_target_with_noise(X_class, y_class, target_count, noise_std=0.05):
    current = len(X_class)
    if current >= target_count:
        return X_class[:target_count], y_class[:target_count]

    repeat_factor = target_count // current
    remainder = target_count % current

    # ë³µì œ
    X_aug = X_class.repeat((repeat_factor, 1, 1))
    y_aug = y_class.repeat(repeat_factor)

    # Gaussian noise ì¶”ê°€
    noise = torch.randn_like(X_aug) * noise_std
    X_aug = X_aug + noise

    # ë‚˜ë¨¸ì§€ ìƒ˜í”Œë„ ì¶”ê°€
    if remainder > 0:
        X_extra = X_class[:remainder]
        noise_extra = torch.randn_like(X_extra) * noise_std
        X_extra = X_extra + noise_extra

        X_aug = torch.cat([X_aug, X_extra], dim=0)
        y_aug = torch.cat([y_aug, y_class[:remainder]], dim=0)

    return X_aug, y_aug

# ë³µì‚¬ë³¸ì—ë§Œ timeshift ì¶”ê°€ í•¨ìˆ˜
def time_shift(X_class, shift_max=10):
    B, C, T = X_class.shape
    shifted = torch.zeros_like(X_class)
    for i in range(B):
        shift = np.random.randint(-shift_max, shift_max + 1)
        if shift > 0:
            shifted[i, :, shift:] = X_class[i, :, :-shift]
        elif shift < 0:
            shifted[i, :, :shift] = X_class[i, :, -shift:]
        else:
            shifted[i] = X_class[i]
    return shifted
def augment_to_target_with_shift(X_class, y_class, target_count, shift_max=10):
    current = len(X_class)
    if current >= target_count:
        return X_class[:target_count], y_class[:target_count]

    repeat_factor = target_count // current
    remainder = target_count % current

    X_aug = X_class.repeat((repeat_factor, 1, 1))
    y_aug = y_class.repeat(repeat_factor)

    # ì‹œê°„ ì´ë™ ì ìš©
    X_aug = time_shift(X_aug, shift_max=shift_max)

    if remainder > 0:
        X_extra = time_shift(X_class[:remainder], shift_max=shift_max)
        X_aug = torch.cat([X_aug, X_extra], dim=0)
        y_aug = torch.cat([y_aug, y_class[:remainder]], dim=0)

    return X_aug, y_aug    



# 6. ì¦ê°• ìˆ˜í–‰
X_normal_aug,  y_normal_aug  = augment_to_target(X_normal,  y_normal,  target_per_class[0])
X_crackle_aug, y_crackle_aug = augment_to_target(X_crackle, y_crackle, target_per_class[1])
X_wheeze_aug,  y_wheeze_aug  = augment_to_target(X_wheeze,  y_wheeze,  target_per_class[2])

# 7. ìµœì¢… í•™ìŠµ ë°ì´í„° êµ¬ì„±
X_train = torch.cat([X_normal_aug, X_crackle_aug, X_wheeze_aug], dim=0)
y_train = torch.cat([y_normal_aug, y_crackle_aug, y_wheeze_aug], dim=0)

print("âœ… ì¦ê°• ì™„ë£Œ:", Counter(y_train.tolist()))


# DataLoader
train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True, drop_last=True)
val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32, drop_last=False)

# ë””ë°”ì´ìŠ¤ ì„¤ì • ë° ëª¨ë¸ ì´ˆê¸°í™”
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
current_dropout = 0.3
model = EnhancedCNNEnsemble(num_classes=3, dropout=current_dropout).to(device)

# FocalLoss í´ë˜ìŠ¤ ì •ì˜
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        CE_loss = nn.functional.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')
        pt = torch.exp(-CE_loss)  # Probability of correct class
        F_loss = (1 - pt) ** self.gamma * CE_loss

        if self.reduction == 'mean':
            return F_loss.mean()
        elif self.reduction == 'sum':
            return F_loss.sum()
        else:
            return F_loss

# EarlyStopping í´ë˜ìŠ¤ ì •ì˜
class EarlyStopping:
    def __init__(self, patience=5, verbose=False, delta=0):
        self.patience = patience
        self.verbose = verbose
        self.delta = delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_model = None

    def __call__(self, val_score, model):
        score = val_score

        if self.best_score is None:
            self.best_score = score
            self.best_model = model.state_dict()
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                print(f"ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´íŠ¸: {self.counter}/{self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.best_model = model.state_dict()
            self.counter = 0


# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
total = sum(target_per_class.values())
ce_weights = torch.tensor([
    total / target_per_class[0],
    total / target_per_class[1],
    total / target_per_class[2]
])
ce_weights = ce_weights / ce_weights.mean()  # ì •ê·œí™”
ce_weights = ce_weights.to(device)

criterion = FocalLoss(alpha=ce_weights, gamma=1.0)
optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)

# ì„±ëŠ¥ì´ ì •ì²´ë˜ë©´ í•™ìŠµë¥ ì„ 0.5ë°°ë¡œ ê°ì†Œ
scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)

# threshold ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_with_threshold(logits, thresholds):
    probs = torch.softmax(logits, dim=1)
    preds = torch.zeros(len(probs), dtype=torch.long)
    
    for i, p in enumerate(probs):
        over_th = (p >= thresholds).nonzero(as_tuple=True)[0]
        if len(over_th) > 0:
            preds[i] = over_th[torch.argmax(p[over_th])]
        else:
            preds[i] = torch.argmax(p)
    return preds

# threshold íƒìƒ‰ í•¨ìˆ˜
def find_best_thresholds(model, dataloader, device):
    model.eval()
    all_logits, all_labels = [], []
    
    with torch.no_grad():
        for xb, yb in dataloader:
            xb = xb.to(device)
            logits = model(xb)
            all_logits.append(logits.cpu())
            all_labels.append(yb)
    
    logits = torch.cat(all_logits)
    labels = torch.cat(all_labels)
    
    best_f1 = 0
    best_thresholds = torch.tensor([0.5, 0.5, 0.5])  # ì´ˆê¸°ê°’
    
    for t0 in np.arange(0.1, 0.9, 0.05):
        for t1 in np.arange(0.1, 0.9, 0.05):
            for t2 in np.arange(0.1, 0.9, 0.05):
                thresholds = torch.tensor([t0, t1, t2])
                preds = predict_with_threshold(logits, thresholds)
                f1 = f1_score(labels, preds, average="macro")
                
                if f1 > best_f1:
                    best_f1 = f1
                    best_thresholds = thresholds
    
    print(f"ğŸ”¥ Best Thresholds: {best_thresholds.tolist()}, Best F1: {best_f1:.4f}")
    return best_thresholds

# val accuracy ê³„ì‚° í•¨ìˆ˜
def calculate_val_accuracy(model, val_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device)
            outputs = model(xb)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == yb).sum().item()
            total += yb.size(0)
    return correct / total

# í‰ê°€ í•¨ìˆ˜
def evaluate(model, dataloader, device):
    model.eval()
    all_preds, all_labels = [], []
    total_loss = 0
    with torch.no_grad():
        for xb, yb in dataloader:
            xb = xb.to(device)
            yb = yb.to(device)
            logits = model(xb)
            loss = criterion(logits, yb)
            total_loss += loss.item()

            preds = torch.argmax(logits, dim=1)
            all_preds.append(preds.cpu())
            all_labels.append(yb.cpu())

    y_true = torch.cat(all_labels).numpy()
    y_pred = torch.cat(all_preds).numpy()

    print(classification_report(y_true, y_pred, target_names=["Normal", "Crackle", "Wheeze"], zero_division=0))
    print("â–¶ Predicted:", Counter(y_pred))
    print("â–¶ Ground truth:", Counter(y_true))

    avg_loss = total_loss / len(dataloader)
    return f1_score(y_true, y_pred, average="macro"), avg_loss

# ì„±ëŠ¥ ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
train_f1_scores = []
val_f1_scores = []
train_accuracies = []
val_accuracies = []

# dropout ë³€ê²½ ì‹œì  ê¸°ë¡ìš© ë¦¬ìŠ¤íŠ¸
dropout_change_epochs = []
dropout_changed = False

# EarlyStopping ì´ˆê¸°í™”
early_stopper = EarlyStopping(patience=6, verbose=True)

# best_val ì´ˆê¸°í™”
best_val_f1 = 0.0

# í•™ìŠµ ë£¨í”„
for epoch in range(30):
    model.train()
    total_loss = 0
    correct_train = 0
    total_train = 0
    for xb, yb in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
        xb, yb = xb.to(device), yb.to(device)
        logits = model(xb)
        loss = criterion(logits, yb)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

        # ì •í™•ë„ ê³„ì‚° (train ë°ì´í„°)
        _, preds = torch.max(logits, 1)
        correct_train += torch.sum(preds == yb)
        total_train += yb.size(0)

    # í•™ìŠµ í›„ í‰ê°€
    train_f1, _ = evaluate(model, train_loader, device)
    val_f1, val_loss = evaluate(model, val_loader, device)

    # í˜„ì¬ í•™ìŠµë¥  í™•ì¸
    current_lr = optimizer.param_groups[0]['lr']
    print(f"[Epoch {epoch+1}] Loss: {total_loss/len(train_loader):.4f} | Val F1: {val_f1:.4f} | LR: {current_lr:.6f}")
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ë™ì‘
    scheduler.step(val_f1)

    if val_f1 > best_val_f1:
        best_val_f1 = val_f1
        torch.save(model.state_dict(), "results/best_model.pth")
        print(f"Best model saved at Epoch {epoch+1} (Val F1: {val_f1:.4f})")

    # EarlyStopping ì²´í¬ ë° Dropout ì¡°ì •
    if early_stopper.counter >= 3 and not dropout_changed:
        current_dropout = 0.2
        dropout_changed_epoch = epoch + 1
        dropout_change_epochs.append(dropout_changed_epoch)
        dropout_changed = True

        print(f"ğŸ” Early stop ì¹´ìš´í„° {early_stopper.counter} â†’ Dropoutì„ {current_dropout}ë¡œ ë³€ê²½")
        
        # ëª¨ë¸ ì¬ìƒì„± ë° ê°€ì¤‘ì¹˜ ì´ì „
        model = EnhancedCNNEnsemble(num_classes=3, dropout=current_dropout).to(device)
        model.load_state_dict(early_stopper.best_model)

        # Optimizer ì¬ì„¤ì •
        optimizer = optim.Adam(model.parameters(), lr=current_lr, weight_decay=1e-5)

    # ì„±ëŠ¥ ê¸°ë¡
    train_f1_scores.append(train_f1)
    val_f1_scores.append(val_f1)
    
    # ì •í™•ë„ ê³„ì‚°
    train_accuracy = correct_train.item() / total_train
    val_accuracy = calculate_val_accuracy(model, val_loader, device)

    train_accuracies.append(train_accuracy)
    val_accuracies.append(val_accuracy)

    print(f"[Epoch {epoch+1}] Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f} | Train Accuracy: {train_accuracy:.4f} | Val Accuracy: {val_accuracy:.4f}")

    
    # ì–¼ë¦¬ìŠ¤íƒ‘
    early_stopper(val_f1, model)

    if early_stopper.early_stop:
        print("ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ë§Œì¡±. í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        model.load_state_dict(early_stopper.best_model)
        break


#best_thresholds = find_best_thresholds(model, val_loader, device)
manual_thresholds = torch.tensor([0.5, 0.45, 0.4])

# ì ìš©í•´ì„œ ì˜ˆì¸¡
model.eval()
with torch.no_grad():
    logits = model(X_val.to(device))
    preds = predict_with_threshold(logits, manual_thresholds)

# í‰ê°€
print(classification_report(y_val.numpy(), preds.numpy(), target_names=["Normal", "Crackle", "Wheeze"]))


# ì •ë³´ë“¤
print("\nğŸ“Œ Training Completed.")
print(f"Final Thresholds: {manual_thresholds.tolist()}")
print(f"Class Weights (ce_weights): {ce_weights.tolist()}")
print(f"Focal Loss Gamma: {criterion.gamma}")

# ì„±ëŠ¥ ì‹œê°í™” (F1-score & Accuracy)
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(train_f1_scores) + 1), train_f1_scores, label="Train F1-score", marker='o')
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label="Train Accuracy", marker='o')
plt.plot(range(1, len(val_f1_scores) + 1), val_f1_scores, label="Validation F1-score", marker='o')

# Dropout ì¡°ì • ì‹œì  í‘œì‹œ
if 'dropout_changed_epoch' in locals():
    for i, change_epoch in enumerate(dropout_change_epochs):
        plt.axvline(x=change_epoch, color='orange', linestyle='--',
                    label=f'Dropout changed (Epoch {change_epoch})' if i == 0 else None)

plt.xlabel('Epoch')
plt.ylabel('Score')
plt.title('Training & Validation F1-score / Accuracy')
plt.legend()
plt.show()

'''
# Feature Map ì‹œê°í™”
def visualize_feature_maps(model, input_tensor, device, title_prefix=""):
    model.eval()
    input_tensor = input_tensor.unsqueeze(0).to(device)  # (1, 13, 253)
    
    activations = {}

    def hook_fn(module, input, output):
        activations['conv1'] = output.cpu()

    # Conv1dë§Œ hook
    handle = model.conv1[0].register_forward_hook(hook_fn)

    with torch.no_grad():
        _ = model(input_tensor)

    handle.remove()

    feature_maps = activations['conv1'][0]  # shape: (C, T)

    num_maps = min(8, feature_maps.shape[0])
    plt.figure(figsize=(15, 5))
    for i in range(num_maps):
        plt.subplot(1, num_maps, i + 1)
        plt.imshow(feature_maps[i].unsqueeze(0), aspect='auto', origin='lower', cmap='viridis')
        plt.title(f"Filter {i}")
        plt.axis('off')
    plt.suptitle(f"{title_prefix} - Feature Maps from Conv1")
    plt.tight_layout()
    plt.show()

# ê° í´ë˜ìŠ¤ë³„ ëŒ€í‘œ sample ì¶”ì¶œ
for label, name in zip([0, 1, 2], ["Normal", "Crackle", "Wheeze"]):
    idx = (y_val == label).nonzero(as_tuple=True)[0][0]
    sample = X_val[idx]
    visualize_feature_maps(model, sample, device, title_prefix=name)
'''